{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import functools\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numba_scipy\n",
    "import gc\n",
    "import os\n",
    "from utils import save_checkpoint_withEval as save_checkpoint\n",
    "from utils import restore_checkpoint_withEval as restore_checkpoint\n",
    "import datasets\n",
    "import tensorflow as tf\n",
    "from torch.utils.cpp_extension import load\n",
    "from models import ncsnpp\n",
    "from configs.vp import cifar10_ncsnpp_continuous as configLoader\n",
    "from models import utils as mutils\n",
    "from models.ema import ExponentialMovingAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = nn.functional.softplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ML model from Song et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config =  configLoader.get_config()\n",
    "config.training.batch_size=128\n",
    "config.training.snapshot_freq_for_preemption=1000\n",
    "config.training.snapshot_freq=50000\n",
    "config.training.log_freq=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data.dataset='MNIST'\n",
    "config.data.image_size=32\n",
    "config.data.num_channels=1\n",
    "config.data.random_flip=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify observation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('forwardSolution.npz', allow_pickle=True)\n",
    "cumSolArray=data['cumSolArray']\n",
    "brTable=data['brTable']\n",
    "observationTimes=data['observationTimes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tEnd = observationTimes[-1]\n",
    "T = len(observationTimes)\n",
    "observationTimes = np.hstack((0, observationTimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(observationTimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = mutils.create_model(config)\n",
    "score_fn = mutils.get_model_fn(score_model, train=True)\n",
    "optimizer = torch.optim.Adam(score_model.parameters(),lr=config.optim.lr) \n",
    "ema = ExponentialMovingAverage(score_model.parameters(), decay=config.model.ema_rate)\n",
    "state = dict(optimizer=optimizer, model=score_model, ema=ema, lossHistory=[], step=0)\n",
    "\n",
    "workdir = 'blackout-mnist'\n",
    "\n",
    "checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "checkpoint_meta_dir = os.path.join(workdir, \"checkpoints-meta\", \"checkpoint.pth\")\n",
    "tf.io.gfile.makedirs(checkpoint_dir)\n",
    "tf.io.gfile.makedirs(os.path.dirname(checkpoint_meta_dir))\n",
    "\n",
    "#checkpoint_resumed = os.path.join(workdir, \"checkpoints\", \"checkpoint_5.pth\")\n",
    "#state = restore_checkpoint(checkpoint_resumed, state, config.device)\n",
    "\n",
    "state = restore_checkpoint(checkpoint_meta_dir, state, config.device)\n",
    "initial_step = int(state['step'])\n",
    "lossHistory = state['lossHistory']\n",
    "evalLossHistory = state['evalLossHistory']\n",
    "ema.copy_to(score_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize train/test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emaFunc(x, r):\n",
    "    \n",
    "    output = np.zeros_like(x)\n",
    "    \n",
    "    output[0] = x[0]\n",
    "    \n",
    "    for i in range(1, len(x)):\n",
    "        \n",
    "        output[i] = (1.0-r)*output[i-1] + (r)*x[i]\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "onset = 80_000\n",
    "samplingRate = 100\n",
    "emaRate = 0.01\n",
    "plt.plot(onset/1000+1./1000*samplingRate*np.arange(len(lossHistory[onset::samplingRate][:])), np.array(emaFunc(lossHistory[onset::samplingRate][:],emaRate)), label='Train')\n",
    "plt.plot(onset/1000+1./1000*samplingRate*np.arange(len(evalLossHistory[onset//samplingRate:])), np.array(emaFunc(evalLossHistory[onset//samplingRate:], emaRate)), label='Test')\n",
    "plt.legend(loc='best')\n",
    "plt.title(f'Iteration={len(lossHistory)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom,poisson\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation='binomial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observationTimesGPU = torch.from_numpy(observationTimes[1:]).to(config.device)\n",
    "\n",
    "targetN = 60_000\n",
    "ensN = 512\n",
    "skipped=1\n",
    "\n",
    "torch.cuda.set_device(config.device)\n",
    "batchN = int(np.ceil(targetN/ensN))\n",
    "state = torch.cuda.FloatTensor(ensN*batchN, 1,32,32).zero_()\n",
    "identity = torch.from_numpy(np.ones((ensN,))).long().to(config.device)\n",
    "u = torch.cuda.FloatTensor(ensN,1,32,32,256).uniform_()\n",
    "\n",
    "n_ma = np.zeros((ensN,1,32,32,256))\n",
    "\n",
    "summary = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for jj in range(batchN):\n",
    "    \n",
    "        t0 = time()\n",
    "        \n",
    "        for i in range(T-1, -1, -skipped):\n",
    "\n",
    "            if np.mod(i+1,50)==0:\n",
    "                \n",
    "                print(f'reverse pass, tIndex={i}, t={observationTimes[i]}, {torch.max(state).detach().cpu().numpy()}')\n",
    "            \n",
    "            t = observationTimes[i+1]\n",
    "            s = observationTimes[i+1-skipped]\n",
    "\n",
    "            pt = np.exp(-t)\n",
    "            ps = np.exp(-s)\n",
    "            \n",
    "            width = 1.0\n",
    "            mean_v = 1.0/2*pt\n",
    "            \n",
    "            ind = i*identity\n",
    "            \n",
    "            dn = softplus(score_fn((state[jj*ensN:(jj+1)*ensN,:,:,:]-mean_v)/width, ind))\n",
    "            \n",
    "            # Binomial bride sampling, GPU implementation\n",
    "            \n",
    "            if generation=='binomial':\n",
    "                \n",
    "                dnNP = np.clip(np.round(dn.detach().cpu().numpy()).astype('int'), 0, np.around(1-state[jj*ensN:(jj+1)*ensN,:,:,:].detach().cpu().numpy())).astype('int')\n",
    "\n",
    "                pp = (np.exp(-s) - np.exp(-t))/(1-np.exp(-t))\n",
    "\n",
    "                drawNP = binom(dnNP, pp).rvs() \n",
    "                \n",
    "            elif generation=='poisson':\n",
    "                \n",
    "                drawNP = poisson(dn.detach().cpu().numpy() * (ps-pt)/(1-pt)).rvs() \n",
    "                \n",
    "            else:\n",
    "                \n",
    "                raise NotImplementedError(f'Sampling method is not implemented.')\n",
    "            \n",
    "            state[jj*ensN:(jj+1)*ensN,:,:,:] = (state[jj*ensN:(jj+1)*ensN,:,:,:] + torch.from_numpy(drawNP).to(config.device)).clip(0,1)\n",
    "    \n",
    "        t1 = time()\n",
    "        print( f'round {jj}, time elapsed={t1-t0}')            \n",
    "\n",
    "        totalState = state.detach().cpu().numpy()\n",
    "        generatedFileName=f'blackout-MNIST-samples-uint8-{targetN}'\n",
    "        np.savez(generatedFileName, np.transpose(totalState[:targetN, :, :, :], (0,2,3,1)).astype('uint8'))\n",
    "    \n",
    "generatedFileName += '.npz'\n",
    "print('saved:  '+ generatedFileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchSDE",
   "language": "python",
   "name": "torchsde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
