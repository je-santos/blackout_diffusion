{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import special as sf\n",
    "from scipy.stats import binom as spbinom\n",
    "#from numba import njit,float64,int64,jit\n",
    "#from numba.types import UniTuple\n",
    "from matplotlib import pyplot as plt\n",
    "#import numba_scipy\n",
    "import gc\n",
    "import os\n",
    "from utils import save_checkpoint_withEval as save_checkpoint\n",
    "from utils import restore_checkpoint_withEval as restore_checkpoint\n",
    "from loadDataPipeline import generateData\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.optimize import bisect\n",
    "from scipy.stats import binom\n",
    "\n",
    "from torch import Tensor \n",
    "\n",
    "import sys\n",
    "sys.path.append('score_sde_pytorch/')\n",
    "\n",
    "softplus = nn.functional.softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "#from score_sde_pytorch.models import ncsnpp\n",
    "from configs.vp import cifar10_ncsnpp_continuous as configLoader\n",
    "from models import utils as mutils\n",
    "from models.ema import ExponentialMovingAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ML model from Song et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configLoader.get_config()\n",
    "config.training.batch_size = 128\n",
    "config.training.snapshot_freq_for_preemption = 10\n",
    "config.training.snapshot_freq = 50_000\n",
    "config.training.log_freq = 100\n",
    "\n",
    "\n",
    "config.data.dataset = 'CELEBA'\n",
    "config.data.image_size = 64\n",
    "config.data.data_path = '/project/smartFRACs/jesantos/generative-discrete-state-diffusion-models/dataBuffer/celebA/celebA_64_64.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.num_scales = 1_000\n",
    "config.model.t_end = 15\n",
    "config.model.num_bins = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for observation times (noise schedule) and forward solution or directly loading previously saved ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class blackout_loader(Dataset)\n",
    "\n",
    "    def __init__(self,  config):\n",
    "        \n",
    "        self.T = config.model.num_scales\n",
    "        self.t_end = config.model.t_end\n",
    "        self.batch_size = config.training.batch_size\n",
    "        \n",
    "        forward_solution(self, config)\n",
    "        compute_weights()\n",
    "        self.load_data()\n",
    "        \n",
    "    def forward_solution(self):\n",
    "       \n",
    "        num_bins = 256\n",
    "        \n",
    "        x_end = np.exp( -self.t_end )\n",
    "        f_grid = np.linspace( -f(self.x_end), f(self.x_end), self.T )\n",
    "        x_grid = np.array( [bisect(lambda x: f(x)-f_grid[i], x_end/2, 1-x_end/2) for i in range(self.T)] )\n",
    "        self.observation_times = -np.log(x_grid)    \n",
    "\n",
    "        table = np.zeros((num_bins, num_bins))\n",
    "        for n in range(num_bins):\n",
    "            for m in range(n):\n",
    "                table[n, m] = n - m\n",
    "            table[n, n] = 0\n",
    "        self.table = np.repeat(table[:, :, None], T, axis=-1)\n",
    "\n",
    "        support = np.arange(num_bins)\n",
    "        sol = np.zeros((T+1, num_bins, num_bins))\n",
    "        sol[0,:,:] = np.eye(num_bins)\n",
    "\n",
    "        self.pt = np.exp(-observation_times)\n",
    "        for t in range(T):\n",
    "            p = pt[t]\n",
    "            sol[t + 1, :, :] = binom.pmf(support, num_bins, 1 - p)\n",
    "        self.cumulative = np.cumsum(sol, axis=1)    \n",
    "        \n",
    "        return\n",
    "        \n",
    "    def compute_weights(self):\n",
    "        \n",
    "        e_observation_times = np.insert(self.observation_times, 0, 0)\n",
    "\n",
    "        #self.pt = torch.exp(-e_observation_times[1:])\n",
    "        self.sampling_prob = torch.ones_like(pt) / torch.sum(torch.ones_like(pt))\n",
    "        self.weights = pt*np.diff(e_observation_times)/sampling_prob\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = np.load(config.data.data_path)\n",
    "        self.training_ims = im.shape[0]\n",
    "        self.num_batches = int( self.training_ims/self.batch_size )\n",
    "        return \n",
    "        \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "            return self.num_batches\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        ims_ind =  torch.randperm( self.training_ims )[:self.batch_size]\n",
    "        ims = self.data[ims_ind]\n",
    "        \n",
    "        t_ind = np.random.choice(self.T, size=(self.batch_size,1,1,1), p=self.sampling_prob)\n",
    "        cp = self.cumulative[t_ind,:,ims]\n",
    "        u = torch.FloatTensor(self.batch_size, 64, 64, 3).uniform_()\n",
    "        nt = torch.argmax(u < cp, axis=4).int()\n",
    "        index = ims*256*self.T + nt*self.T + t_ind\n",
    "        \n",
    "        \n",
    "        birth_rate = self.table[index]  \n",
    "        p = self.pt[t_ind]\n",
    "        mean_v = (255/2*p).reshape((n, 1, 1, 1))\n",
    "        \n",
    "        \n",
    "        return ((nt-mean_v)/width).permute((0,3,1,2)), birthRateBatch.permute((0,3,1,2)), tIndex\n",
    "    \n",
    "    \n",
    "    def one_batch(self):\n",
    "        return None\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = blackout_loader(config, batch_size=None, pin_memory=True, num_workers=16, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_GPU = next(train_iter)\n",
    "train_batch = train_batch_GPU.numpy()\n",
    "\n",
    "output_image_batch, brRate_batch, tIndexArray = generateBatchDataGPU(train_batch_GPU, T)\n",
    "\n",
    "output_image_batch = np.transpose(output_image_batch.detach().cpu().numpy(), (0,2,3,1))\n",
    "brRate_batch = np.transpose(brRate_batch.detach().cpu().numpy(), (0,2,3,1))\n",
    "tIndexArray = tIndexArray.detach().cpu().numpy()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    testImage = train_batch[i,:,:,:]\n",
    "    \n",
    "    \n",
    "    output_image = (255.0*(output_image_batch[i,:,:,:]+1.)/2.).astype('int32')\n",
    "    birthRate = brRate_batch[i,:,:,:]\n",
    "    targetTime = tIndexArray[i]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize=(4.8,1.5))\n",
    "    \n",
    "    ax[0].imshow(testImage)\n",
    "    \n",
    "    if np.amax(output_image)!=0:\n",
    "        ax[1].imshow(output_image/np.amax(output_image))\n",
    "    else:\n",
    "        ax[1].imshow(output_image)\n",
    "        \n",
    "    ax[1].set_title('$t='+str(targetTime)+'$')\n",
    "    \n",
    "    if np.amax(birthRate)-np.amin(birthRate)!=0:\n",
    "        ax[2].imshow((birthRate-np.amin(birthRate))/(np.amax(birthRate)-np.amin(birthRate)))\n",
    "    else:\n",
    "        ax[2].imshow(birthRate)\n",
    "        \n",
    "    for j in range(3):\n",
    "        \n",
    "        ax[j].set_xticklabels('')\n",
    "        ax[j].set_yticklabels('')\n",
    "    \n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an ML model to learn the transition rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = mutils.create_model(config)\n",
    "score_fn = mutils.get_model_fn(score_model, train=True)\n",
    "optimizer = torch.optim.Adam(score_model.parameters(),lr=config.optim.lr) \n",
    "\n",
    "ema = ExponentialMovingAverage(score_model.parameters(), decay=config.model.ema_rate)\n",
    "\n",
    "train_batch = next(train_iter).to(config.device).float()\n",
    "train_batch = train_batch.permute(0, 3, 1, 2)\n",
    "imgBatch = train_batch\n",
    "\n",
    "workdir = 'blackout-celebA64'\n",
    "\n",
    "state = dict(optimizer=optimizer, model=score_model, ema=ema, lossHistory=[], evalLossHistory=[], step=0)\n",
    "\n",
    "checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "checkpoint_meta_dir = os.path.join(workdir, \"checkpoints-meta\", \"checkpoint.pth\")\n",
    "tf.io.gfile.makedirs(checkpoint_dir)\n",
    "tf.io.gfile.makedirs(os.path.dirname(checkpoint_meta_dir))\n",
    "state = restore_checkpoint(checkpoint_meta_dir, state, config.device)\n",
    "initial_step = int(state['step'])\n",
    "lossHistory = state['lossHistory']\n",
    "evalLossHistory = state['evalLossHistory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step in range(initial_step, config.training.n_iters):\n",
    "    \n",
    "    try:\n",
    "        train_batch = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        train_batch = next(train_iter)\n",
    "        \n",
    "    output_image_batch, birthRate_batch, tIndexArray = generateBatchDataGPU(train_batch, T)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y = softplus(score_fn(output_image_batch, tIndexArray))\n",
    "    \n",
    "    loss = torch.mean( weightsGPU[tIndexArray.long()].reshape([config.training.batch_size,1,1,1])*(y - birthRate_batch*torch.log(y)))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    state['ema'].update(state['model'].parameters())\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    lossHistory.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    if step != 0 and step % config.training.snapshot_freq_for_preemption == 0:\n",
    "        save_checkpoint(checkpoint_meta_dir, state)\n",
    "        \n",
    "    if step != 0 and step % config.training.snapshot_freq == 0 or step == config.training.n_iters:\n",
    "        save_step = step // config.training.snapshot_freq\n",
    "        save_checkpoint(os.path.join(checkpoint_dir, f'checkpoint_{save_step}.pth'), state)    \n",
    "    \n",
    "    if np.mod(step, config.training.log_freq)==0:\n",
    "        \n",
    "        ema.store(score_model.parameters())\n",
    "        ema.copy_to(score_model.parameters())\n",
    "        \n",
    "        y = softplus(score_fn(output_image_batch, tIndexArray))\n",
    "        \n",
    "        loss = torch.mean( weightsGPU[tIndexArray.long()].reshape([config.training.batch_size,1,1,1])*(y - birthRate_batch*torch.log(y)))\n",
    "    \n",
    "        ema.restore(score_model.parameters())\n",
    "        \n",
    "        evalLossHistory.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        print(f'current iter: {step}, loss: {lossHistory[-1]}, eval loss: {evalLossHistory[-1]}')\n",
    "        \n",
    "    state['step'] = step\n",
    "    state['lossHistory'] = lossHistory\n",
    "    state['evalLossHistory'] = evalLossHistory\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf]",
   "language": "python",
   "name": "conda-env-.conda-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
