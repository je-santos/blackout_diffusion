{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import special as sf\n",
    "from scipy.stats import binom as spbinom\n",
    "from numba import njit,float64,int64,jit\n",
    "from numba.types import UniTuple\n",
    "from matplotlib import pyplot as plt\n",
    "import numba_scipy\n",
    "import gc\n",
    "import os\n",
    "from utils import save_checkpoint_withEval as save_checkpoint\n",
    "from utils import restore_checkpoint_withEval as restore_checkpoint\n",
    "from loadDataPipeline import generateData\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = nn.functional.softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "from models import ncsnpp\n",
    "from configs.vp import cifar10_ncsnpp_continuous as configLoader\n",
    "from models import utils as mutils\n",
    "from models.ema import ExponentialMovingAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ML model from Song et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config =  configLoader.get_config()\n",
    "config.training.batch_size=100\n",
    "config.training.snapshot_freq_for_preemption=10\n",
    "config.training.snapshot_freq=50000\n",
    "config.training.log_freq=100\n",
    "config.data.dataset='CELEBA'\n",
    "config.data.image_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tEnd = 15.\n",
    "T = 1000\n",
    "config.model.num_scales=T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataBuffers/celebA/celebA_64_64.npy')\n",
    "\n",
    "\n",
    "test_with = 0\n",
    "batch_sh  = data.shape[0]-test_with\n",
    "print(f'Getting {batch_sh} samples')\n",
    "\n",
    "train_loader = DataLoader(data[:batch_sh,], \n",
    "                          batch_size=config.training.batch_size, \n",
    "                          pin_memory=True, \n",
    "                          num_workers=0,\n",
    "                          shuffle=True,\n",
    "\n",
    "\n",
    "                          drop_last=True\n",
    "                          )\n",
    "\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for observation times (noise schedule) and forward solution or directly loading previously saved ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    data = np.load('forwardSolution.npz', allow_pickle=True)\n",
    "    cumSolArray=data['cumSolArray']\n",
    "    brTable=data['brTable']\n",
    "    observationTimes=data['observationTimes']    \n",
    "    \n",
    "except FileNotFoundError:\n",
    "\n",
    "    from scipy.optimize import bisect\n",
    "\n",
    "    def f(x):\n",
    "        return np.log(x/(1-x))\n",
    "\n",
    "    xEnd = np.exp(-tEnd)\n",
    "    fGrid = np.linspace(-f(xEnd), f(xEnd), T)\n",
    "    xGrid = np.array([bisect(lambda x: f(x)-fGrid[i], xEnd/2, 1-xEnd/2) for i in range(T)])\n",
    "    observationTimes = -np.log(xGrid)    \n",
    "    \n",
    "    ### Analytically derived reverse-time transition rate\n",
    "    brTable = np.zeros((256,256,T))\n",
    "    for tIndex in range(T):\n",
    "        p = np.exp(-observationTimes[tIndex])\n",
    "        for n in range(256):\n",
    "            for m in range(n):\n",
    "                brTable[n,m,tIndex] = n-m \n",
    "            brTable[n,n,tIndex] = 0\n",
    "\n",
    "    ### Analytical forward solution, PDF\n",
    "    from scipy.stats import binom\n",
    "\n",
    "    support = np.arange(0,256)\n",
    "    solArray = np.zeros((T+1, 256, 256))\n",
    "    solArray[0,:,:] = np.eye(256)\n",
    "\n",
    "    for tIndex in range(T):\n",
    "        p = np.exp(-observationTimes[tIndex])\n",
    "        for IC in range(256):\n",
    "            solArray[tIndex+1,:,IC] =  binom(IC, p).pmf(support)    \n",
    "            \n",
    "    ### Analytical forward solution, CDF\n",
    "    cumSolArray = np.zeros_like(solArray)\n",
    "\n",
    "    for i in range(solArray.shape[0]):\n",
    "        for j in range(solArray.shape[1]):\n",
    "            cumSolArray[i,:,j] = np.cumsum(solArray[i,:,j] )    \n",
    "            \n",
    "    np.savez('forwardSolution.npz', cumSolArray=cumSolArray, brTable=brTable, observationTimes=observationTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(observationTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumSolArrayGPU = torch.from_numpy(cumSolArray).to(config.device)\n",
    "brTableGPU = torch.from_numpy(np.ravel(brTable)).to(config.device)\n",
    "observationTimeGPU = torch.from_numpy(observationTimes).to(config.device)\n",
    "eobservationTimes = np.hstack([0, observationTimes])\n",
    "\n",
    "offset = 0.01\n",
    "\n",
    "ps = np.exp(-eobservationTimes[:-1])\n",
    "pt = np.exp(-eobservationTimes[1:])\n",
    "\n",
    "samplingProb = np.ones_like(pt)\n",
    "samplingProb /= np.sum(samplingProb)\n",
    "\n",
    "pi = samplingProb\n",
    "\n",
    "weights = pt*(eobservationTimes[1:]-eobservationTimes[:-1])/pi\n",
    "weightsGPU = torch.from_numpy(weights).to(config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( weightsGPU.detach().cpu().numpy() )\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBatchDataGPU(imgBatch,T):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        n,nx,ny,nc = imgBatch.shape\n",
    "        imgBatchGPU = imgBatch.to(config.device).long()\n",
    "        tIndex = torch.from_numpy(np.random.choice(T, size=(n,1,1,1), p=samplingProb)).to(config.device)\n",
    "        \n",
    "        cp = cumSolArrayGPU[(tIndex+1).long(),:,imgBatchGPU.long()]\n",
    "        u = torch.cuda.FloatTensor(n,nx,ny,nc,1).uniform_().to(config.device)\n",
    "        \n",
    "        nt =  torch.argmax((u < cp).long(), axis=4).int()\n",
    "        index = imgBatchGPU*256*T + nt*T + tIndex.long()\n",
    "        birthRateBatch = brTableGPU[index.long()]  \n",
    "    \n",
    "        p = torch.exp(-observationTimeGPU[tIndex.long()])\n",
    "        width = 1.0 \n",
    "        mean_v = (255.0/2*p).reshape((n, 1, 1, 1))\n",
    "        \n",
    "        return ((nt-mean_v)/width).permute((0,3,1,2)).to(torch.float32), birthRateBatch.permute((0,3,1,2)).to(torch.float32), tIndex[:,0,0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch_GPU = next(train_iter)\n",
    "train_batch = train_batch_GPU.numpy()\n",
    "\n",
    "output_image_batch, brRate_batch, tIndexArray = generateBatchDataGPU(train_batch_GPU, T)\n",
    "\n",
    "output_image_batch = np.transpose(output_image_batch.detach().cpu().numpy(), (0,2,3,1))\n",
    "brRate_batch = np.transpose(brRate_batch.detach().cpu().numpy(), (0,2,3,1))\n",
    "tIndexArray = tIndexArray.detach().cpu().numpy()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    testImage = train_batch[i,:,:,:]\n",
    "    \n",
    "    \n",
    "    output_image = (255.0*(output_image_batch[i,:,:,:]+1.)/2.).astype('int32')\n",
    "    birthRate = brRate_batch[i,:,:,:]\n",
    "    targetTime = tIndexArray[i]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize=(4.8,1.5))\n",
    "    \n",
    "    ax[0].imshow(testImage)\n",
    "    \n",
    "    if np.amax(output_image)!=0:\n",
    "        ax[1].imshow(output_image/np.amax(output_image))\n",
    "    else:\n",
    "        ax[1].imshow(output_image)\n",
    "        \n",
    "    ax[1].set_title('$t='+str(targetTime)+'$')\n",
    "    \n",
    "    if np.amax(birthRate)-np.amin(birthRate)!=0:\n",
    "        ax[2].imshow((birthRate-np.amin(birthRate))/(np.amax(birthRate)-np.amin(birthRate)))\n",
    "    else:\n",
    "        ax[2].imshow(birthRate)\n",
    "        \n",
    "    for j in range(3):\n",
    "        \n",
    "        ax[j].set_xticklabels('')\n",
    "        ax[j].set_yticklabels('')\n",
    "    \n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an ML model to learn the transition rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = mutils.create_model(config)\n",
    "score_fn = mutils.get_model_fn(score_model, train=True)\n",
    "optimizer = torch.optim.Adam(score_model.parameters(),lr=config.optim.lr) \n",
    "\n",
    "ema = ExponentialMovingAverage(score_model.parameters(), decay=config.model.ema_rate)\n",
    "\n",
    "train_batch = next(train_iter).to(config.device).float()\n",
    "train_batch = train_batch.permute(0, 3, 1, 2)\n",
    "imgBatch = train_batch\n",
    "\n",
    "workdir = 'blackout-celebA64'\n",
    "\n",
    "state = dict(optimizer=optimizer, model=score_model, ema=ema, lossHistory=[], evalLossHistory=[], step=0)\n",
    "\n",
    "checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "checkpoint_meta_dir = os.path.join(workdir, \"checkpoints-meta\", \"checkpoint.pth\")\n",
    "tf.io.gfile.makedirs(checkpoint_dir)\n",
    "tf.io.gfile.makedirs(os.path.dirname(checkpoint_meta_dir))\n",
    "state = restore_checkpoint(checkpoint_meta_dir, state, config.device)\n",
    "initial_step = int(state['step'])\n",
    "lossHistory = state['lossHistory']\n",
    "evalLossHistory = state['evalLossHistory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step in range(initial_step, config.training.n_iters):\n",
    "    \n",
    "    try:\n",
    "        train_batch = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        train_batch = next(train_iter)\n",
    "        \n",
    "    output_image_batch, birthRate_batch, tIndexArray = generateBatchDataGPU(train_batch, T)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y = softplus(score_fn(output_image_batch, tIndexArray))\n",
    "    \n",
    "    loss = torch.mean( weightsGPU[tIndexArray.long()].reshape([config.training.batch_size,1,1,1])*(y - birthRate_batch*torch.log(y)))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    state['ema'].update(state['model'].parameters())\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    lossHistory.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    if step != 0 and step % config.training.snapshot_freq_for_preemption == 0:\n",
    "        save_checkpoint(checkpoint_meta_dir, state)\n",
    "        \n",
    "    if step != 0 and step % config.training.snapshot_freq == 0 or step == config.training.n_iters:\n",
    "        save_step = step // config.training.snapshot_freq\n",
    "        save_checkpoint(os.path.join(checkpoint_dir, f'checkpoint_{save_step}.pth'), state)    \n",
    "    \n",
    "    if np.mod(step, config.training.log_freq)==0:\n",
    "        \n",
    "        ema.store(score_model.parameters())\n",
    "        ema.copy_to(score_model.parameters())\n",
    "        \n",
    "        y = softplus(score_fn(output_image_batch, tIndexArray))\n",
    "        \n",
    "        loss = torch.mean( weightsGPU[tIndexArray.long()].reshape([config.training.batch_size,1,1,1])*(y - birthRate_batch*torch.log(y)))\n",
    "    \n",
    "        ema.restore(score_model.parameters())\n",
    "        \n",
    "        evalLossHistory.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        print(f'current iter: {step}, loss: {lossHistory[-1]}, eval loss: {evalLossHistory[-1]}')\n",
    "        \n",
    "    state['step'] = step\n",
    "    state['lossHistory'] = lossHistory\n",
    "    state['evalLossHistory'] = evalLossHistory\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchSDE",
   "language": "python",
   "name": "torchsde"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
